{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142671bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from vmdpy import VMD\n",
    "from scipy.fftpack import hilbert,fft,ifft\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68249b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# data = np.loadtxt('ball18.txt')\n",
    "# x = data[0:2048]\n",
    "df = pd.read_csv('solar2019.csv',header=0, parse_dates=[0],index_col=0)# 读取CSV文件，并设置第一列为日期，作为索引\n",
    "# print(df.head(10))\n",
    "x = df.iloc[0:2000,-1].values\n",
    "print(x.shape)\n",
    "tau = 0.  # noise-tolerance (no strict fidelity enforcement)\n",
    "DC = 0  # no DC part imposed\n",
    "init = 1  # initialize omegas uniformly\n",
    "tol = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c347358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X):\n",
    "    K = int(X[0])  # 将X中的第一个元素转换为整数，并赋值给neurons1\n",
    "    alpha = int(X[1])  # 将X中的第二个元素转换为整数，并赋值给neurons2\n",
    "    if K < int(X[0]):\n",
    "        K = int(X[0])\n",
    "    if K > int(X[0]):\n",
    "        K = int(X[0])\n",
    "        \n",
    "    if alpha <int(X[1]):\n",
    "        alpha = int(X[1])\n",
    "    if alpha > int(X[1]):\n",
    "        alpha =int(X[1])\n",
    "    print([K,alpha])  # 打印神经元数量、dropout和batch_size\n",
    "\n",
    "    u, u_hat, omega = VMD(x, alpha, tau, K, DC, init, tol)\n",
    "\n",
    "    EP = []\n",
    "    for i in range(K):\n",
    "        H = np.abs(hilbert(u[i,:]))\n",
    "        e1 = []\n",
    "        for j in range(len(H)):\n",
    "            p = H[j]/np.sum(H)\n",
    "            e = -p*log(p,2)\n",
    "            e1.append(e)\n",
    "        E = np.sum(e1)  \n",
    "        EP.append(E)\n",
    "    s = np.sum(EP)/K\n",
    "    return s  # 返回均方误差作为训练函数的输出\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def fun(K, alpha):\n",
    "#     if K < lb[0]:\n",
    "#         K = lb[0]\n",
    "#     if K > ub[0]:\n",
    "#         K = ub[0]\n",
    "        \n",
    "#     if alpha < lb[1]:\n",
    "#         alpha = lb[1]\n",
    "#     if alpha > ub[1]:\n",
    "#         alpha =ub[1]\n",
    "\n",
    "#     # K = int(position[0])\n",
    "#     # alpha = position[1]\n",
    "#     u, u_hat, omega = VMD(x, alpha, tau, K, DC, init, tol)\n",
    "#     #  \n",
    "#     EP = []\n",
    "#     for i in range(K):\n",
    "#         H = np.abs(hilbert(u[i,:]))\n",
    "#         e1 = []\n",
    "#         for j in range(len(H)):\n",
    "#             p = H[j]/np.sum(H)\n",
    "#             e = -p*log(p,2)\n",
    "#             e1.append(e)\n",
    "#         E = np.sum(e1)  \n",
    "#         EP.append(E)\n",
    "#     s = np.sum(EP)/K\n",
    "#     return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fcec9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSA():\n",
    "    def __init__(self, func, n_dim=None, pop_size=20, max_iter=10, lb=-512, ub=512, verbose=False):\n",
    "        self.func = func\n",
    "        self.n_dim = n_dim  # 粒子的维度，也是目标函数的变量个数\n",
    "        self.pop = pop_size  # 粒子数量\n",
    "        P_percent = 0.2  # # 生产者的人口规模占总人口规模的20%\n",
    "        D_percent = 0.1  # 预警者的人口规模占总人口规模的10%\n",
    "        self.pNum = round(self.pop * P_percent)  # 生产者的人口规模占总人口规模的20%\n",
    "        self.warn = round(self.pop * D_percent)  # 预警者的人口规模占总人口规模的10%\n",
    "\n",
    "        self.max_iter = max_iter  # 最大迭代次数\n",
    "        self.verbose = verbose # 是否打印每次迭代的结果\n",
    "        \n",
    "        # 根据给定的 lb 和 ub 列表设置下界和上界数组\n",
    "        self.lb, self.ub = np.array(lb) * np.ones(self.n_dim), np.array(ub) * np.ones(self.n_dim)\n",
    "        # 检查维度是否等于 lb 和 ub 数组的长度\n",
    "        assert self.n_dim == len(self.lb) == len(self.ub), 'dim == len(lb) == len(ub) is not True'\n",
    "        # 检查所有的上界元素是否大于对应的下界元素\n",
    "        assert np.all(self.ub > self.lb), 'upper-bound must be greater than lower-bound'\n",
    "        # 从下界（self.lb）到上界（self.ub）之间生成服从均匀分布的随机数矩阵\n",
    "        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.pop, self.n_dim))\n",
    "\n",
    "        self.Y = [self.func(self.X[i]) for i in range(len(self.X))]  ## 对于每个粒子，计算其函数值（y = f(x)）\n",
    "        self.pbest_x = self.X.copy() # 每个粒子的个体最佳位置（历史上的最佳位置）\n",
    "        self.pbest_y = [np.inf for i in range(self.pop)]  # 每个粒子的最佳函数值（历史上的最佳函数值）\n",
    "        self.gbest_x = self.pbest_x.mean(axis=0).reshape(1, -1)  # 所有粒子的全局最佳位置\n",
    "        self.gbest_y = np.inf  # 所有粒子的全局最佳函数值\n",
    "        self.gbest_y_hist = []  # 存储每次迭代的全局最佳函数值\n",
    "        self.update_pbest() # 更新每个粒子的个体最佳位置和函数值\n",
    "        self.update_gbest() # 更新全局最佳位置和函数值\n",
    "        #\n",
    "        # 记录详细值\n",
    "        self.record_mode = False\n",
    "        self.record_value = {'X': [], 'V': [], 'Y': []}\n",
    "        self.best_x, self.best_y = self.gbest_x, self.gbest_y  # 为了历史原因，记录最佳位置和函数值（即全局最佳位置和函数值）\n",
    "        # 初始化最大函数值的索引、粒子位置和函数值\n",
    "        self.idx_max = 0\n",
    "        self.x_max = self.X[self.idx_max, :]\n",
    "        self.y_max = self.Y[self.idx_max]\n",
    "\n",
    "    def cal_y(self, start, end): # 计算从索引 start 到索引 end-1 的每个粒子的函数值 Y\n",
    "        # 对于每个索引 i 在 start 和 end-1 之间\n",
    "        for i in range(start, end):\n",
    "            self.Y[i] = self.func(self.X[i])# 计算粒子 X[i] 的函数值并存储在 Y[i] 中\n",
    "        # return self.Y\n",
    "\n",
    "    def update_pbest(self): # 更新每个个体最佳位置（pbest）\n",
    "        '''\n",
    "        个体最佳位置（pbest）\n",
    "        '''\n",
    "        for i in range(len(self.Y)):  # 对于每个索引 i 在 0 到 len(self.Y)-1 之间\n",
    "            # 如果当前粒子的函数值 self.Y[i] 比个体最佳函数值 self.pbest_y[i] 更优\n",
    "            if self.pbest_y[i] > self.Y[i]:\n",
    "                # 更新该粒子的个体最佳位置和函数值\n",
    "                self.pbest_x[i] = self.X[i]\n",
    "                self.pbest_y[i] = self.Y[i]\n",
    "\n",
    "    def update_gbest(self): # 更新全局最佳位置（gbest）\n",
    "        # 找到当前个体最佳函数值中最小值的索引\n",
    "        idx_min = self.pbest_y.index(min(self.pbest_y))\n",
    "        # 如果全局最佳函数值 self.gbest_y 比当前个体最佳函数值中的最小值更优\n",
    "        if self.gbest_y > self.pbest_y[idx_min]:\n",
    "            # 更新全局最佳位置和函数值\n",
    "            self.gbest_x = self.X[idx_min, :].copy()\n",
    "            self.gbest_y = self.pbest_y[idx_min]\n",
    "\n",
    "    def find_worst(self): # 找到当前函数值中的最大值（用于记录最差的个体）\n",
    "        # 找到当前函数值 self.Y 中的最大值的索引\n",
    "        self.idx_max = self.Y.index(max(self.Y))\n",
    "        # 获取对应最大值索引的粒子位置和函数值\n",
    "        self.x_max = self.X[self.idx_max, :]\n",
    "        self.y_max = self.Y[self.idx_max]\n",
    "\n",
    "    def update_finder(self):\n",
    "        r2 = np.random.rand(1)  # 预警值\n",
    "        self.idx = sorted(enumerate(self.Y), key=lambda x: x[1])\n",
    "        self.idx = [self.idx[i][0] for i in range(len(self.idx))]\n",
    "        # 这一部位为发现者（探索者）的位置更新\n",
    "        if r2 < 0.8:  # 预警值较小，说明没有捕食者出现\n",
    "            for i in range(self.pNum):\n",
    "                r1 = np.random.rand(1)\n",
    "                self.X[self.idx[i], :] = self.X[self.idx[i], :] * np.exp(-(i) / (r1 * self.max_iter))  # 对自变量做一个随机变换\n",
    "                self.X = np.clip(self.X, self.lb, self.ub)  # 对超过边界的变量进行去除\n",
    "                # X[idx[i], :] = Bounds(X[idx[i], :], lb, ub)  # 对超过边界的变量进行去除\n",
    "                # fit[sortIndex[0, i], 0] = func(X[sortIndex[0, i], :])  # 算新的适应度值\n",
    "        elif r2 >= 0.8:  # 预警值较大，说明有捕食者出现威胁到了种群的安全，需要去其它地方觅食\n",
    "            for i in range(self.pNum):\n",
    "                Q = np.random.rand(1)  # 也可以替换成  np.random.normal(loc=0, scale=1.0, size=1)\n",
    "                self.X[self.idx[i], :] = self.X[self.idx[i], :] + Q * np.ones(\n",
    "                    (1, self.n_dim))  # Q是服从正态分布的随机数。L表示一个1×d的矩阵\n",
    "                self.X = np.clip(self.X, self.lb, self.ub)  # 对超过边界的变量进行去除\n",
    "                # X[idx[i], :] = Bounds(X[sortIndex[0, i], :], lb, ub)\n",
    "                # fit[sortIndex[0, i], 0] = func(X[sortIndex[0, i], :])\n",
    "        self.cal_y(0, self.pNum)\n",
    "\n",
    "    def update_follower(self): \n",
    "        #  这一部位为加入者（追随者）的位置更新\n",
    "        for ii in range(self.pop - self.pNum):  # 对于每个加入者的索引 ii 在范围 self.pNum 到 self.pop - 1 之间\n",
    "            i = ii + self.pNum  # 计算当前加入者的索引 i\n",
    "            A = np.floor(np.random.rand(1, self.n_dim) * 2) * 2 - 1 # 生成二值随机矩阵 A\n",
    "            best_idx = self.Y[0:self.pNum].index(min(self.Y[0:self.pNum])) # 找到个体最佳函数值中的最小值的索引\n",
    "            bestXX = self.X[best_idx, :] # 获取个体最佳位置\n",
    "            if i > self.pop / 2:  # 如果 i 大于 pop 的一半\n",
    "                Q = np.random.rand(1) # 生成随机数 Q\n",
    "                # 根据公式更新加入者的位置\n",
    "                self.X[self.idx[i], :] = Q * np.exp((self.x_max - self.X[self.idx[i], :]) / np.square(i))\n",
    "            else:\n",
    "                # 根据公式更新加入者的位置\n",
    "                self.X[self.idx[i], :] = bestXX + np.dot(np.abs(self.X[self.idx[i], :] - bestXX),\n",
    "                                                         1 / (A.T * np.dot(A, A.T))) * np.ones((1, self.n_dim))\n",
    "        self.X = np.clip(self.X, self.lb, self.ub)  # 对超过边界的变量进行去除\n",
    "        # X[self.idx[i],:] = Bounds(X[self.idx[i],lb,ub)\n",
    "        # fit[self.idx[i],0] = func(X[self.idx[i], :])\n",
    "        self.cal_y(self.pNum, self.pop) # 计算加入者的函数值\n",
    "\n",
    "    def detect(self): # 检测是否需要进行位置更新\n",
    "        arrc = np.arange(self.pop) # 创建一个包含索引的数组 arrc\n",
    "        c = np.random.permutation(arrc)  # 随机排列序列\n",
    "        b = [self.idx[i] for i in c[0: self.warn]] # 选取排列后的前 self.warn 个索引作为 b\n",
    "        e = 10e-10 # 定义一个很小的数 e\n",
    "        # 对于 b 中的每个索引 j\n",
    "        for j in range(len(b)):\n",
    "            # 如果当前粒子的函数值 self.Y[b[j]] 大于全局最佳函数值 self.gbest_y\n",
    "            if self.Y[b[j]] > self.gbest_y:\n",
    "                # 更新粒子的位置为全局最佳函数值加上一个随机向量\n",
    "                self.X[b[j], :] = self.gbest_y + np.random.rand(1, self.n_dim) * np.abs(self.X[b[j], :] - self.gbest_y)\n",
    "            else:\n",
    "                # 更新粒子的位置为原位置加上一个随机向量\n",
    "                self.X[b[j], :] = self.X[b[j], :] + (2 * np.random.rand(1) - 1) * np.abs(\n",
    "                    self.X[b[j], :] - self.x_max) / (self.func(self.X[b[j]]) - self.y_max + e)\n",
    "            # X[sortIndex[0, b[j]], :] = Bounds(X[sortIndex[0, b[j]], :], lb, ub)\n",
    "            # fit[sortIndex[0, b[j]], 0] = func(X[sortIndex[0, b[j]]])\n",
    "            self.X = np.clip(self.X, self.lb, self.ub)  # 对超过边界的变量进行去除\n",
    "            self.Y[b[j]] = self.func(self.X[b[j]])\n",
    "\n",
    "    def run(self, max_iter=None):\n",
    "        self.max_iter = max_iter or self.max_iter\n",
    "        for iter_num in range(self.max_iter): # 对于每次迭代 iter_num 在范围 0 到 self.max_iter-1 之间\n",
    "            self.update_finder()  # 更新发现者位置\n",
    "            self.find_worst()  # 取出最大的适应度值和最差适应度的X\n",
    "            self.update_follower()  # 更新跟随着位置\n",
    "            self.update_pbest()\n",
    "            self.update_gbest()\n",
    "            self.detect()\n",
    "            self.update_pbest()\n",
    "            self.update_gbest()\n",
    "            self.gbest_y_hist.append(self.gbest_y) # 记录全局最佳函数值的历史记录\n",
    "            # 打印每次迭代的函数值\n",
    "            print(f\"Iteration {iter_num + 1}: {self.gbest_y}\")\n",
    "        return self.best_x, self.best_y # 返回历史上的最佳位置和最佳函数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b30746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 249]\n",
      "[5, 969]\n",
      "[6, 2950]\n",
      "[8, 2474]\n",
      "[7, 1524]\n",
      "[8, 2248]\n",
      "[7, 1203]\n",
      "[2, 1421]\n",
      "[2, 2575]\n",
      "[9, 2976]\n",
      "[9, 2678]\n",
      "[8, 612]\n",
      "[6, 2007]\n",
      "[4, 1895]\n",
      "[6, 632]\n",
      "[3, 2595]\n",
      "[6, 2190]\n",
      "[8, 1539]\n",
      "[5, 1398]\n",
      "[4, 1421]\n",
      "[7, 249]\n",
      "[5, 969]\n",
      "[6, 2950]\n",
      "[8, 2474]\n",
      "[2, 100]\n",
      "[10, 1248]\n",
      "[10, 726]\n",
      "[2, 198]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[8, 612]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 632]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[8, 1540]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 1: 9.932501520378349\n",
      "[5, 210]\n",
      "[2, 2487]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 731]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[8, 576]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 874]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[5, 210]\n",
      "[2, 150]\n",
      "Iteration 2: 9.882829733094658\n",
      "[2, 150]\n",
      "[2, 100]\n",
      "[10, 267]\n",
      "[2, 153]\n",
      "[10, 355]\n",
      "[10, 499]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 499]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "Iteration 3: 9.881598277885232\n",
      "[10, 330]\n",
      "[10, 355]\n",
      "[10, 267]\n",
      "[2, 214]\n",
      "[10, 311]\n",
      "[2, 151]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 152]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "Iteration 4: 9.881598277885232\n",
      "[2, 236]\n",
      "[10, 311]\n",
      "[10, 267]\n",
      "[2, 237]\n",
      "[10, 289]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 328]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 183]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[10, 214]\n",
      "[10, 100]\n",
      "Iteration 5: 9.881598277885232\n",
      "[10, 287]\n",
      "[2, 245]\n",
      "[10, 267]\n",
      "[10, 278]\n",
      "[10, 278]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 236]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 313]\n",
      "[2, 100]\n",
      "[8, 192]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "Iteration 6: 9.881598277885232\n",
      "[10, 277]\n",
      "[10, 274]\n",
      "[10, 267]\n",
      "[10, 273]\n",
      "[4, 262]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 290]\n",
      "[2, 100]\n",
      "[2, 230]\n",
      "[6, 100]\n",
      "[10, 100]\n",
      "[10, 152]\n",
      "Iteration 7: 9.881598277885232\n",
      "[5, 262]\n",
      "[10, 271]\n",
      "[10, 267]\n",
      "[10, 270]\n",
      "[4, 262]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 256]\n",
      "[2, 100]\n",
      "[10, 325]\n",
      "[8, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 8: 9.881598277885232\n",
      "[10, 267]\n",
      "[8, 265]\n",
      "[10, 267]\n",
      "[8, 266]\n",
      "[4, 262]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 350]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 235]\n",
      "[7, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 9: 9.881598277885232\n",
      "[8, 265]\n",
      "[8, 265]\n",
      "[9, 267]\n",
      "[8, 265]\n",
      "[9, 267]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 226]\n",
      "[7, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 183]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 10: 9.881598277885232\n",
      "[10, 267]\n",
      "[9, 267]\n",
      "[9, 267]\n",
      "[8, 265]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[7, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 292]\n",
      "[7, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 221]\n",
      "[2, 100]\n",
      "[10, 351]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 11: 9.881598277885232\n",
      "[9, 267]\n",
      "[9, 267]\n",
      "[9, 267]\n",
      "[10, 269]\n",
      "[2, 183]\n",
      "[2, 184]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 255]\n",
      "[4, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "Iteration 12: 9.881598277885232\n",
      "[6, 181]\n",
      "[9, 267]\n",
      "[9, 267]\n",
      "[9, 100]\n",
      "[10, 145]\n",
      "[10, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 13: 9.881598277885232\n",
      "[6, 181]\n",
      "[2, 100]\n",
      "[10, 183]\n",
      "[10, 100]\n",
      "[8, 130]\n",
      "[9, 100]\n",
      "[10, 101]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 14: 9.881598277885232\n",
      "[2, 100]\n",
      "[10, 104]\n",
      "[10, 141]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 15: 9.881598277885232\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[6, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 16: 9.881598277885232\n",
      "[10, 100]\n",
      "[10, 104]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[10, 102]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 17: 9.881598277885232\n",
      "[10, 100]\n",
      "[7, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 18: 9.881598277885232\n",
      "[10, 100]\n",
      "[7, 100]\n",
      "[9, 100]\n",
      "[7, 100]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "Iteration 19: 9.881598277885232\n",
      "[10, 100]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[7, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 20: 9.881598277885232\n",
      "[10, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "[10, 101]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[8, 100]\n",
      "[2, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 21: 9.881598277885232\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 101]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 22: 9.881598277885232\n",
      "[9, 100]\n",
      "[10, 104]\n",
      "[10, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 23: 9.881598277885232\n",
      "[7, 102]\n",
      "[4, 100]\n",
      "[10, 100]\n",
      "[5, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[9, 100]\n",
      "Iteration 24: 9.881598277885232\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[9, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 25: 9.881598277885232\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[9, 100]\n",
      "[5, 100]\n",
      "[3, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[6, 101]\n",
      "[10, 100]\n",
      "Iteration 26: 9.881598277885232\n",
      "[5, 100]\n",
      "[6, 101]\n",
      "[7, 102]\n",
      "[5, 100]\n",
      "[7, 101]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 101]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 27: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[7, 102]\n",
      "[4, 100]\n",
      "[7, 101]\n",
      "[5, 100]\n",
      "[7, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "Iteration 28: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[7, 101]\n",
      "[4, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 29: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[4, 100]\n",
      "[4, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[8, 103]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 30: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[6, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 31: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 32: 9.881598277885232\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[7, 102]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[7, 102]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[7, 129]\n",
      "[10, 100]\n",
      "Iteration 33: 9.881598277885232\n",
      "[7, 129]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 34: 9.881598277885232\n",
      "[2, 100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[3, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 35: 9.881598277885232\n",
      "[6, 101]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[4, 100]\n",
      "[6, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[7, 102]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 36: 9.881598277885232\n",
      "[6, 101]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[9, 100]\n",
      "[7, 102]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 37: 9.881598277885232\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "Iteration 38: 9.881598277885232\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[3, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[4, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 39: 9.881598277885232\n",
      "[5, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[3, 100]\n",
      "[4, 100]\n",
      "[5, 100]\n",
      "[6, 101]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[5, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[7, 102]\n",
      "[2, 100]\n",
      "[2, 100]\n",
      "[10, 100]\n",
      "[10, 100]\n",
      "Iteration 40: 9.881598277885232\n",
      "代码执行时间： 770.8192195892334 秒\n",
      "best_params is  [  5.68226445 100.        ]\n",
      "best_precision is 9.881598277885232\n"
     ]
    }
   ],
   "source": [
    "# 定义参数的上限\n",
    "UP = [10, 3000]\n",
    "# 定义参数的下限\n",
    "DOWN = [2, 100]\n",
    "start_time = time.time()  # 记录开始时间\n",
    "# 创建 SSA 对象，设置参数并进行优化\n",
    "ssa = SSA(training, n_dim=2, pop_size=20, max_iter=40, lb=DOWN, ub=UP)\n",
    "ssa.run()\n",
    "end_time = time.time()  # 记录结束时间\n",
    "execution_time = end_time - start_time  # 计算代码执行时间\n",
    "print(\"代码执行时间：\", execution_time, \"秒\")\n",
    "# 打印最优参数\n",
    "print('best_params is ', ssa.gbest_x)\n",
    "# 打印最优精度\n",
    "print('best_precision is',ssa.gbest_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f74c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数： 1\n",
      "迭代次数： 2\n",
      "迭代次数： 3\n",
      "迭代次数： 4\n",
      "Number of evaluations:  40\n",
      "Best =  6 -2144.6085258688863 \n",
      " fmin =  9.956738005023835\n",
      "[    6.31682999 -2144.60852587]\n",
      "迭代次数： 1\n",
      "迭代次数： 2\n",
      "迭代次数： 3\n",
      "迭代次数： 4\n",
      "Number of evaluations:  40\n",
      "Best =  9 588.6268530411858 \n",
      " fmin =  10.101025406741659\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random as rand\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from vmdpy import VMD\n",
    "from scipy.fftpack import hilbert,fft,ifft\n",
    "from math import log\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('solar2019.csv',header=0, parse_dates=[0],index_col=0)# 读取CSV文件，并设置第一列为日期，作为索引\n",
    "# print(df.head(10))\n",
    "x = df.iloc[0:2000,-1].values\n",
    "\n",
    "\n",
    "tau = 0.  # noise-tolerance (no strict fidelity enforcement)\n",
    "DC = 0  # no DC part imposed\n",
    "init = 1  # initialize omegas uniformly\n",
    "tol = 1e-7\n",
    "\n",
    "#========参数设置==============\n",
    "# objfun:目标函数\n",
    "# N_pop: 种群规模，通常为10到40\n",
    "# N_gen: 迭代数\n",
    "# A: 响度（恒定或降低）\n",
    "# r: 脉冲率（恒定或减小）\n",
    "# 此频率范围决定范围\n",
    "# 如有必要，应更改这些值\n",
    "# Qmin: 频率最小值\n",
    "# Qmax: 频率最大值\n",
    "# d: 维度\n",
    "# lower: 下界\n",
    "# upper: 上界\n",
    "\n",
    "def bat_algorithm(objfun, N_pop=10, N_gen=4, A=0.5, r=0.5,\n",
    "    Qmin=0, Qmax=2, d=2, lower=[3,100], upper=[10,3000]):\n",
    "\n",
    "    N_iter = 0\n",
    "\n",
    "    # 速度上下限\n",
    "    Lower_bound = lower * np.ones((1,d))\n",
    "    Upper_bound = upper * np.ones((1,d))\n",
    "\n",
    "    Q = np.zeros((N_pop, 1)) # 频率\n",
    "    v = np.zeros((N_pop, d)) # 速度\n",
    "    S = np.zeros((N_pop, d))\n",
    "\n",
    "    # 初始化种群、初始解\n",
    "\n",
    "    Sol = np.zeros((N_pop, d))\n",
    "    Fitness = np.zeros((N_pop, 1))\n",
    "    for i in range(N_pop):\n",
    "        Sol[i] = np.random.uniform(Lower_bound, Upper_bound, (1, d))\n",
    "        Fitness[i] = objfun(Sol[i])\n",
    "\n",
    "    # 找出初始最优解\n",
    "    fmin = min(Fitness)\n",
    "    Index = list(Fitness).index(fmin)\n",
    "    best = Sol[Index]\n",
    "\n",
    "    # 迭代\n",
    "    for t in range(N_gen):\n",
    "        print('迭代次数：',t+1)\n",
    "\n",
    "        for i in range(N_pop):\n",
    "\n",
    "            Q[i] = np.random.uniform(Qmin, Qmax)\n",
    "            v[i] = v[i] + (Sol[i] - best) * Q[i]\n",
    "            S[i] = Sol[i] + v[i]\n",
    "\n",
    "            # 界限限制\n",
    "            Sol[i] = simplebounds(Sol[i], Lower_bound, Upper_bound)\n",
    "            # Pulse rate\n",
    "            if rand() > r:\n",
    "\n",
    "                S[i] = best + 0.001*np.random.randn(1, d)\n",
    "\n",
    "            #====评估新的解决方案 ===========\n",
    "            # print(i)\n",
    "            Fnew = objfun(S[i])\n",
    "            #====如果解决方案有所改进，或者声音不太大，请更新====\n",
    "            if (Fnew <= Fitness[i]) and (rand() < A):\n",
    "                Sol[i] = S[i]\n",
    "                Fitness[i] = Fnew\n",
    "\n",
    "            #====更新当前的最佳解决方案======\n",
    "            if Fnew <= fmin:\n",
    "                best = S[i]\n",
    "                fmin = Fnew\n",
    "\n",
    "        N_iter = N_iter + N_pop\n",
    "\n",
    "    print('Number of evaluations: ', N_iter)\n",
    "    print(\"Best = \", int(best[0]),best[1], '\\n fmin = ', fmin)\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def simplebounds(s, Lower_bound, Upper_bound):\n",
    "\n",
    "    Index = s > Lower_bound\n",
    "    s = Index * s + ~Index * Lower_bound\n",
    "    Index = s < Upper_bound\n",
    "    s = Index * s + ~Index * Upper_bound\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "#====目标函数=============\n",
    "def test_function(u):\n",
    "    low = [3,100]\n",
    "    ub = [10,3000]\n",
    "    K = int(u[0])\n",
    "    alpha = u[1]\n",
    "    if K < low[0]:\n",
    "        K = low[0]\n",
    "    if K > ub[0]:\n",
    "        K = ub[0]\n",
    "\n",
    "    if alpha < low[1]:\n",
    "        alpha = low[1]\n",
    "    if alpha > ub[1]:\n",
    "        alpha =ub[1]\n",
    "\n",
    "\n",
    "    u, u_hat, omega = VMD(x, alpha, tau, K, DC, init, tol)\n",
    "    #\n",
    "    EP = []\n",
    "    for i in range(K):\n",
    "        H = np.abs(hilbert(u[i,:]))\n",
    "        e1 = []\n",
    "        for j in range(len(H)):\n",
    "            p = H[j]/np.sum(H)\n",
    "            e = -p*log(p,2)\n",
    "            e1.append(e)\n",
    "        E = np.sum(e1)\n",
    "        EP.append(E)\n",
    "    s = np.sum(EP)/K\n",
    "    return s\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(bat_algorithm(test_function))\n",
    "    bat_algorithm(test_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f190bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 100], [10, 3000]]\n",
      "6 2406.023117363554\n",
      "5 2764.019315752946\n",
      "9 1109.4121163773411\n",
      "3 254.2201598049656\n",
      "4 1947.5801994178626\n",
      "7 2072.845961972953\n",
      "5 1270.962380972338\n",
      "7 847.5727103299198\n",
      "5 1040.4299964320464\n",
      "4 2413.3257725332674\n",
      "3 1593.4648917345978\n",
      "4 2166.278349908661\n",
      "8 2652.2775719854144\n",
      "4 2948.202438307074\n",
      "7 1229.7124323570522\n",
      "9 1271.2385954281285\n",
      "5 2610.705428587702\n",
      "3 504.3805725774293\n",
      "3 1500.1262734945883\n",
      "6 2402.540978502412\n",
      "7 2256.620619802535\n",
      "4 657.2442281798837\n",
      "4 1724.9557785522693\n",
      "6 1959.386638574193\n",
      "9 234.4537640431314\n",
      "5 1487.371453259424\n",
      "4 2445.4796865047483\n",
      "7 1415.5906813789124\n",
      "8 1806.986036643306\n",
      "9 2491.6485199573253\n",
      "6 1300.6119429083244\n",
      "4 1776.807955602152\n",
      "6 840.2097456355932\n",
      "7 2673.5331619142717\n",
      "7 998.7181659465074\n",
      "9 2980.1746195146584\n",
      "8 1108.9464588375631\n",
      "4 1438.7942981749893\n",
      "9 1920.5376406573912\n",
      "6 1968.112461185557\n",
      "8 1424.755010255144\n",
      "4 673.6259665253531\n",
      "4 2915.9501941314693\n",
      "8 552.8164128869712\n",
      "9 1244.3563557527011\n",
      "7 2934.994252653389\n",
      "6 2270.7720136007742\n",
      "7 491.9326663728926\n",
      "5 1345.6345515545768\n",
      "6 696.1401561185298\n",
      "8 2780.602011186702\n",
      "4 1201.5156414586556\n",
      "7 1822.8688506278984\n",
      "8 2450.4368973176574\n",
      "9 1812.8579158487114\n",
      "7 1352.0111732995952\n",
      "9 1950.9040153609667\n",
      "8 1347.5761706867368\n",
      "6 186.40585274679398\n",
      "3 502.25201861791317\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "当前最小适应度： nan\n",
      "迭代次数： 0\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 1\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JetBrains\\ANACONDA\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 2\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 3\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 4\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 5\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 6\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 7\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 8\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 9\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 10\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 11\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 12\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 13\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 14\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 15\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 16\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 17\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 18\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 19\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 20\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 21\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 22\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 23\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 24\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 25\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 26\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 27\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 28\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 29\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 30\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 31\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 32\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 33\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 34\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 35\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 36\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 37\n",
      "nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 38\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "迭代次数： 39\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Optimal solution is: 6 2406.023117363554\n"
     ]
    }
   ],
   "source": [
    "##GA优化\n",
    "\n",
    "# from sklearn import svm\n",
    "# import numpy as np\n",
    "# from numpy.random import random as rand\n",
    "# import random\n",
    "# import math\n",
    "# from matplotlib import pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from vmdpy import VMD\n",
    "# from scipy.fftpack import hilbert,fft,ifft\n",
    "# from math import log\n",
    "# import pandas as pd\n",
    "# import copy\n",
    "\n",
    "\n",
    "# df = pd.read_csv('solar2019.csv',header=0, parse_dates=[0],index_col=0)# 读取CSV文件，并设置第一列为日期，作为索引\n",
    "# # print(df.head(10))\n",
    "# x = df.iloc[0:2000,-1].values\n",
    "\n",
    "\n",
    "# tau = 0.  # noise-tolerance (no strict fidelity enforcement)\n",
    "# DC = 0  # no DC part imposed\n",
    "# init = 1  # initialize omegas uniformly\n",
    "# tol = 1e-7\n",
    " \n",
    "\n",
    "\n",
    "# def Fun(vardim, x, bound):\n",
    "    \n",
    "#     K = int(x[0])\n",
    "#     alpha = x[1]\n",
    "    \n",
    "#     if K < low[0]:\n",
    "#         K = low[0]\n",
    "#     if K > ub[0]:\n",
    "#         K = ub[0]\n",
    "        \n",
    "#     if alpha < low[1]:\n",
    "#         alpha = low[1]\n",
    "#     if alpha > ub[1]:\n",
    "#         alpha =ub[1]  \n",
    "\n",
    "    \n",
    "#     u, u_hat, omega = VMD(x, alpha, tau, K, DC, init, tol)\n",
    "#     #  平均包络熵\n",
    "#     EP = []\n",
    "#     for i in range(K):\n",
    "#         H = np.abs(hilbert(u[i,:]))\n",
    "#         e1 = []\n",
    "#         for j in range(len(H)):\n",
    "#             p = H[j]/np.sum(H)\n",
    "#             e = -p*log(p,2)\n",
    "#             e1.append(e)\n",
    "#         E = np.sum(e1)  \n",
    "#         EP.append(E)\n",
    "#     s = np.sum(EP)/K\n",
    "#     return s\n",
    "    \n",
    "\n",
    "\n",
    "# class GAIndividual:\n",
    "#     '''\n",
    "    \n",
    "#     创建pop中的单个个体\n",
    "#     '''\n",
    "#     def __init__(self, vardim, bound):\n",
    "        \n",
    "#         self.vardim = vardim\n",
    "#         self.bound = bound\n",
    "#         self.fitness = 0\n",
    "\n",
    "#     def generate(self):\n",
    "#         '''\n",
    "#         generate a random chromsome for genetic algorithm\n",
    "#         '''\n",
    "#         len = self.vardim\n",
    "#         rnd = np.random.random(size=len)\n",
    "#         self.chrom = np.zeros(len)\n",
    "#         for i in range(0, len):\n",
    "#             self.chrom[i] = self.bound[0][i] + \\\n",
    "#                 (self.bound[1][i] - self.bound[0][i]) * rnd[i]\n",
    "#         print(int(self.chrom[0]),self.chrom[1])\n",
    "\n",
    "#     def calculateFitness(self):\n",
    "#         '''\n",
    "#         calculate the fitness of the chromsome\n",
    "#         '''\n",
    "#         self.fitness = Fun(self.vardim, self.chrom, self.bound)\n",
    "#         print(self.fitness)\n",
    "        \n",
    "\n",
    "# class GeneticAlgorithm:\n",
    "    \n",
    "#     def __init__(self, sizepop, vardim, bound, MAXGEN, params):\n",
    "#         '''\n",
    "#         sizepop: population sizepop\n",
    "#         vardim: dimension of variables\n",
    "#         bound: boundaries of variables\n",
    "#         MAXGEN: termination condition\n",
    "#         param: algorithm required parameters, it is a list which is consisting \n",
    "#                of crossover rate, mutation rate, alpha\n",
    "#         '''\n",
    "#         self.sizepop = sizepop\n",
    "#         self.MAXGEN = MAXGEN\n",
    "#         self.vardim = vardim\n",
    "#         self.bound = bound\n",
    "#         self.population = []\n",
    "#         self.fitness = np.zeros((self.sizepop, 1))\n",
    "#         self.trace = np.zeros((self.MAXGEN, 2))\n",
    "#         self.params = params\n",
    "\n",
    "#     def initialize(self):\n",
    "        \n",
    "#         for i in range(0, self.sizepop):\n",
    "#             ind = GAIndividual(self.vardim, self.bound)\n",
    "#             ind.generate()\n",
    "#             self.population.append(ind)\n",
    "\n",
    "#     def evaluate(self):\n",
    "        \n",
    "#         for i in range(0, self.sizepop):\n",
    "#             self.population[i].calculateFitness()\n",
    "#             self.fitness[i] = self.population[i].fitness\n",
    "\n",
    "#     def solve(self):\n",
    "        \n",
    "#         self.t = 0 # 迭代次数\n",
    "#         self.initialize() # 初始化种群\n",
    "#         self.evaluate() # 计算适应度\n",
    "#         best = np.min(self.fitness) #选出适应度最小的个体\n",
    "#         print(\"当前最小适应度：\",best)\n",
    "#         bestIndex = np.argmin(self.fitness) # 最小适应度的索引\n",
    "#         self.best = copy.deepcopy(self.population[bestIndex]) \n",
    "#         self.avefitness = np.mean(self.fitness) # 平均适应度\n",
    "#         self.BEST = []\n",
    "#         while (self.t < self.MAXGEN):\n",
    "#             print('迭代次数：',self.t)\n",
    "#             self.t += 1\n",
    "#             self.selectionOperation() # 选择\n",
    "#             self.crossoverOperation() # 交叉\n",
    "#             self.mutationOperation()  # 变异\n",
    "#             self.evaluate()           # 重新计算新种群适应度\n",
    "#             best = np.min(self.fitness)\n",
    "#             bestIndex = np.argmin(self.fitness)\n",
    "#             if best < self.best.fitness:\n",
    "#                 self.best = copy.deepcopy(self.population[bestIndex])\n",
    "#             self.avefitness = np.mean(self.fitness)\n",
    "#             self.BEST.append(self.best)\n",
    "           \n",
    "#         print(\"Optimal solution is:\", int(self.best.chrom[0]),self.best.chrom[1])\n",
    "        \n",
    "\n",
    "#     def selectionOperation(self):\n",
    "#         '''\n",
    "#         selection operation for Genetic Algorithm\n",
    "#         '''\n",
    "#         newpop = []\n",
    "#         totalFitness = np.sum(self.fitness)\n",
    "#         accuFitness = np.zeros((self.sizepop, 1))\n",
    "\n",
    "#         # 适应度的累进占比\n",
    "#         sum1 = 0.\n",
    "#         for i in range(0, self.sizepop):\n",
    "#             accuFitness[i] = sum1 + self.fitness[i] / totalFitness\n",
    "#             sum1 = accuFitness[i]\n",
    "\n",
    "#         # 随机选出新种群的索引\n",
    "#         for i in range(0, self.sizepop):\n",
    "#             r = random.random()\n",
    "#             idx = 0\n",
    "#             for j in range(0, self.sizepop - 1):\n",
    "#                 if j == 0 and r < accuFitness[j]:\n",
    "#                     idx = 0\n",
    "#                     break\n",
    "#                 elif r >= accuFitness[j] and r < accuFitness[j + 1]:\n",
    "#                     idx = j + 1\n",
    "#                     break\n",
    "#             newpop.append(self.population[idx])\n",
    "#         self.population = newpop\n",
    "\n",
    "#     def crossoverOperation(self):\n",
    "#         '''\n",
    "#         crossover operation for genetic algorithm\n",
    "#         '''\n",
    "#         newpop = []\n",
    "#         # 选出两个个体进行交换\n",
    "#         for i in range(0, self.sizepop, 2):\n",
    "#             idx1 = random.randint(0, self.sizepop - 1)\n",
    "#             idx2 = random.randint(0, self.sizepop - 1)\n",
    "#             while idx2 == idx1:\n",
    "#                 idx2 = random.randint(0, self.sizepop - 1)\n",
    "#             newpop.append(copy.deepcopy(self.population[idx1]))\n",
    "#             newpop.append(copy.deepcopy(self.population[idx2]))\n",
    "#             r = random.random()\n",
    "            \n",
    "#             if r < self.params[0]:\n",
    "#                 crossPos = random.randint(1, self.vardim - 1)\n",
    "#                 for j in range(crossPos, self.vardim):\n",
    "                   \n",
    "#                     newpop[i].chrom[j] = newpop[i].chrom[j] * self.params[2] +\\\n",
    "#                         (1 - self.params[2]) * newpop[i + 1].chrom[j]\n",
    "                    \n",
    "#                     newpop[i + 1].chrom[j] = newpop[i + 1].chrom[j] * self.params[2] + \\\n",
    "#                         (1 - self.params[2]) * newpop[i].chrom[j]\n",
    "#         self.population = newpop\n",
    "\n",
    "#     def mutationOperation(self):\n",
    "#         '''\n",
    "#         mutation operation for genetic algorithm\n",
    "#         '''\n",
    "#         newpop = []\n",
    "#         for i in range(0, self.sizepop):\n",
    "#             newpop.append(copy.deepcopy(self.population[i]))\n",
    "#             r = random.random()\n",
    "#             if r < self.params[1]:\n",
    "#                 mutatePos = random.randint(0, self.vardim - 1)\n",
    "#                 theta = random.random()\n",
    "#                 if theta > 0.5:\n",
    "                    \n",
    "#                     newpop[i].chrom[mutatePos] = newpop[i].chrom[mutatePos] - \\\n",
    "#                         (newpop[i].chrom[mutatePos] - self.bound[0][mutatePos]) * \\\n",
    "#                             (1 - random.random()**(1 - self.t / self.MAXGEN))\n",
    "#                 else:\n",
    "                   \n",
    "#                     newpop[i].chrom[mutatePos] = newpop[i].chrom[mutatePos] + \\\n",
    "#                         (self.bound[1][mutatePos] - newpop[i].chrom[mutatePos]) * \\\n",
    "#                             (1 - random.random()**(1 - self.t / self.MAXGEN))\n",
    "#         self.population = newpop\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     low = [3,100]\n",
    "#     ub = [10, 3000]\n",
    "#     bound = [low,ub]\n",
    "#     print(bound)\n",
    "#     # def __init__(self, sizepop, vardim, bound, MAXGEN, params):\n",
    "#     ga = GeneticAlgorithm(60, 2, bound, 40, [0.9, 0.1, 0.5])\n",
    "#     ga.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d2526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
